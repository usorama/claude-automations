# üß† PRISM Unified Intelligence System
## Complete Implementation with Automatic Collection & Observable Results

**Version**: 3.0  
**Date**: August 24, 2025  
**Principle**: "Nothing fails silently. Everything is observable. Intelligence is automatic."

---

## üéØ The Master Plan: All Three Options, Unified

We're implementing ALL options in a unified system that:
1. **Completes PRISM** with SQLite intelligence database
2. **Activates existing** components immediately  
3. **Builds future features** with cross-repository intelligence
4. **Prevents silent failures** with comprehensive monitoring
5. **Provides observable results** through real-time dashboard

---

## üèóÔ∏è System Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    PRISM INTELLIGENCE CORE                  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ   Collection   ‚îÇ   Processing  ‚îÇ   Learning   ‚îÇ Observability‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Auto-Collectors‚îÇ Relevance     ‚îÇ Pattern      ‚îÇ Dashboard    ‚îÇ
‚îÇ Event Hooks    ‚îÇ Scoring       ‚îÇ Recognition  ‚îÇ Alerts       ‚îÇ
‚îÇ Interceptors   ‚îÇ Optimization  ‚îÇ Prediction   ‚îÇ Metrics      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚Üì
                    SQLite Intelligence Database
                              ‚Üì
                 ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                 ‚îÇ   Observable Results API     ‚îÇ
                 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üìä Component 1: Automatic Intelligence Collection

### **1.1 Collection Interceptor** (Makes everything automatic)

```python
# prism/src/auto_collector.py

import sqlite3
import json
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, Optional
import functools
import time

class PRISMCollector:
    """Automatically collects intelligence from EVERY agent execution"""
    
    def __init__(self):
        self.db_path = Path.home() / '.claude' / 'prism' / 'intelligence.db'
        self.db_path.parent.mkdir(parents=True, exist_ok=True)
        self.init_database()
        self.collection_active = True
        
    def init_database(self):
        """Initialize SQLite database with schema"""
        with sqlite3.connect(self.db_path) as conn:
            with open('database/schema.sql', 'r') as f:
                conn.executescript(f.read())
    
    def intercept_agent(self, agent_func):
        """Decorator that automatically collects intelligence from any agent"""
        @functools.wraps(agent_func)
        def wrapper(*args, **kwargs):
            if not self.collection_active:
                return agent_func(*args, **kwargs)
            
            # Pre-execution collection
            session_id = self.generate_session_id()
            start_time = time.time()
            agent_type = kwargs.get('agent_type', 'unknown')
            task = kwargs.get('task', '')
            
            # Capture context loading
            context_before = self.capture_context_state()
            
            try:
                # Execute agent
                result = agent_func(*args, **kwargs)
                success = True
                error_message = None
                
            except Exception as e:
                result = None
                success = False
                error_message = str(e)
                
                # Create alert for failure
                self.create_alert('error', f'Agent {agent_type} failed', {
                    'error': str(e),
                    'task': task
                })
            
            finally:
                # Post-execution collection
                execution_time = int((time.time() - start_time) * 1000)
                context_after = self.capture_context_state()
                
                # Store intelligence
                self.record_usage(
                    session_id=session_id,
                    agent_type=agent_type,
                    task=task,
                    context_before=context_before,
                    context_after=context_after,
                    execution_time=execution_time,
                    success=success,
                    error_message=error_message
                )
                
                # Learn from this execution
                self.update_learning_patterns(agent_type, task, success)
                
            return result
        
        return wrapper
    
    def capture_context_state(self) -> Dict:
        """Capture current context state"""
        manifest_dir = Path.home() / '.claude' / 'manifests'
        loaded_manifests = []
        total_size = 0
        
        if manifest_dir.exists():
            for manifest_file in manifest_dir.glob('*.json'):
                size = manifest_file.stat().st_size / 1024  # KB
                loaded_manifests.append(manifest_file.stem)
                total_size += size
        
        return {
            'manifests': loaded_manifests,
            'total_size_kb': total_size,
            'timestamp': datetime.now().isoformat()
        }
    
    def record_usage(self, **kwargs):
        """Record context usage to database"""
        with sqlite3.connect(self.db_path) as conn:
            conn.execute("""
                INSERT INTO context_usage 
                (session_id, agent_type, task_description, manifests_loaded, 
                 manifests_used, context_size_kb, execution_time_ms, success, error_message)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                kwargs['session_id'],
                kwargs['agent_type'],
                kwargs['task'][:500],  # Truncate long tasks
                json.dumps(kwargs['context_before']['manifests']),
                json.dumps(kwargs['context_after']['manifests']),
                kwargs['context_before']['total_size_kb'],
                kwargs['execution_time'],
                kwargs['success'],
                kwargs['error_message']
            ))
    
    def create_alert(self, severity: str, message: str, details: Dict):
        """Create an alert for observable issues"""
        with sqlite3.connect(self.db_path) as conn:
            conn.execute("""
                INSERT INTO alerts (severity, component, message, details)
                VALUES (?, ?, ?, ?)
            """, (severity, 'prism', message, json.dumps(details)))
        
        # Also trigger notification if critical
        if severity in ['error', 'critical']:
            self.notify_user(severity, message)
    
    def notify_user(self, severity: str, message: str):
        """Send notification to user (audio + terminal)"""
        import subprocess
        
        # Audio alert
        subprocess.run(['say', f"PRISM Alert: {message}"], capture_output=True)
        
        # Terminal notification
        print(f"\n{'='*60}")
        print(f"üö® PRISM {severity.upper()}: {message}")
        print(f"{'='*60}\n")
```

### **1.2 Universal Hook Integration** (Automatic activation)

```python
# prism/hooks/universal_interceptor.py

#!/usr/bin/env python3
"""Universal interceptor that makes ALL intelligence collection automatic"""

import sys
import os
from pathlib import Path

# Add PRISM to path
sys.path.append(str(Path.home() / 'claude-automations' / 'prism' / 'src'))

from auto_collector import PRISMCollector

# Initialize collector
collector = PRISMCollector()

# Monkey-patch the Task tool to intercept ALL agent executions
original_task = __builtins__.get('Task')

def intercepted_task(*args, **kwargs):
    """Intercepted Task tool that collects intelligence"""
    # Extract agent information
    agent_type = kwargs.get('subagent_type', 'unknown')
    task = kwargs.get('prompt', '')[:200]
    
    # Add to kwargs for collector
    kwargs['agent_type'] = agent_type
    kwargs['task'] = task
    
    # Wrap with collector
    if original_task:
        wrapped = collector.intercept_agent(original_task)
        return wrapped(*args, **kwargs)
    
    return original_task(*args, **kwargs) if original_task else None

# Replace Task globally
__builtins__['Task'] = intercepted_task

print("[PRISM] Universal intelligence collection activated")
```

---

## üîç Component 2: Observable Results Dashboard

### **2.1 Real-time Terminal Dashboard**

```python
# prism/src/dashboard.py

import sqlite3
from datetime import datetime, timedelta
from pathlib import Path
from rich.console import Console
from rich.table import Table
from rich.live import Live
from rich.layout import Layout
from rich.panel import Panel
import time

class PRISMDashboard:
    """Real-time observable metrics dashboard"""
    
    def __init__(self):
        self.console = Console()
        self.db_path = Path.home() / '.claude' / 'prism' / 'intelligence.db'
        
    def get_metrics(self) -> Dict:
        """Get current metrics from database"""
        with sqlite3.connect(self.db_path) as conn:
            # Overall stats
            overall = conn.execute("""
                SELECT 
                    COUNT(*) as total_tasks,
                    SUM(CASE WHEN success = 1 THEN 1 ELSE 0 END) as successful,
                    AVG(context_size_kb) as avg_context,
                    AVG(execution_time_ms) as avg_time
                FROM context_usage
                WHERE timestamp > datetime('now', '-24 hours')
            """).fetchone()
            
            # Recent failures
            failures = conn.execute("""
                SELECT timestamp, agent_type, error_message
                FROM context_usage
                WHERE success = 0
                ORDER BY timestamp DESC
                LIMIT 5
            """).fetchall()
            
            # Unacknowledged alerts
            alerts = conn.execute("""
                SELECT severity, message, timestamp
                FROM alerts
                WHERE acknowledged = 0
                ORDER BY timestamp DESC
                LIMIT 5
            """).fetchall()
            
            # Agent performance
            agents = conn.execute("""
                SELECT 
                    agent_type,
                    COUNT(*) as tasks,
                    AVG(context_size_kb) as avg_context,
                    (SUM(CASE WHEN success = 1 THEN 1 ELSE 0 END) * 100.0 / COUNT(*)) as success_rate
                FROM context_usage
                WHERE timestamp > datetime('now', '-24 hours')
                GROUP BY agent_type
                ORDER BY tasks DESC
                LIMIT 5
            """).fetchall()
            
        return {
            'overall': overall,
            'failures': failures,
            'alerts': alerts,
            'agents': agents
        }
    
    def create_dashboard(self) -> Layout:
        """Create dashboard layout"""
        layout = Layout()
        
        metrics = self.get_metrics()
        
        # Overall stats panel
        overall = metrics['overall']
        stats_table = Table(title="24-Hour Statistics")
        stats_table.add_column("Metric", style="cyan")
        stats_table.add_column("Value", style="green")
        
        if overall:
            success_rate = (overall[1] / overall[0] * 100) if overall[0] > 0 else 0
            stats_table.add_row("Total Tasks", str(overall[0]))
            stats_table.add_row("Success Rate", f"{success_rate:.1f}%")
            stats_table.add_row("Avg Context Size", f"{overall[2]:.1f} KB")
            stats_table.add_row("Avg Execution Time", f"{overall[3]:.0f} ms")
        
        # Failures panel
        failures_table = Table(title="Recent Failures", style="red")
        failures_table.add_column("Time", style="yellow")
        failures_table.add_column("Agent", style="cyan")
        failures_table.add_column("Error", style="red")
        
        for failure in metrics['failures']:
            failures_table.add_row(
                failure[0][-8:],  # Time only
                failure[1],
                failure[2][:50] if failure[2] else "Unknown"
            )
        
        # Alerts panel
        alerts_table = Table(title="Active Alerts", style="yellow")
        alerts_table.add_column("Severity", style="red")
        alerts_table.add_column("Message", style="yellow")
        
        for alert in metrics['alerts']:
            alerts_table.add_row(alert[0].upper(), alert[1])
        
        # Agent performance
        agents_table = Table(title="Agent Performance")
        agents_table.add_column("Agent", style="cyan")
        agents_table.add_column("Tasks", style="white")
        agents_table.add_column("Success", style="green")
        agents_table.add_column("Avg Context", style="blue")
        
        for agent in metrics['agents']:
            agents_table.add_row(
                agent[0],
                str(agent[1]),
                f"{agent[3]:.1f}%",
                f"{agent[2]:.1f} KB"
            )
        
        # Combine into layout
        layout.split_column(
            Layout(Panel(stats_table, title="PRISM Intelligence Dashboard")),
            Layout(name="middle").split_row(
                Layout(Panel(agents_table)),
                Layout(Panel(failures_table))
            ),
            Layout(Panel(alerts_table))
        )
        
        return layout
    
    def run_live(self):
        """Run live dashboard"""
        with Live(self.create_dashboard(), refresh_per_second=1) as live:
            while True:
                time.sleep(1)
                live.update(self.create_dashboard())
```

### **2.2 Slash Command for Dashboard**

```markdown
# prism/commands/prism.md
---
description: PRISM Intelligence Dashboard - View real-time metrics and alerts
---

# PRISM Intelligence Dashboard

View real-time intelligence metrics, failures, and alerts.

## Commands:
- `/prism status` - Show current metrics
- `/prism alerts` - View unacknowledged alerts
- `/prism learn` - Show learning patterns
- `/prism health` - System health check

$ARGUMENTS
```

---

## ü§ñ Component 3: Failure Prevention & Recovery

### **3.1 Health Monitor** (Prevents silent failures)

```python
# prism/src/health_monitor.py

import sqlite3
import time
from pathlib import Path
from typing import Dict, List
import subprocess

class PRISMHealthMonitor:
    """Monitors system health and prevents silent failures"""
    
    def __init__(self):
        self.db_path = Path.home() / '.claude' / 'prism' / 'intelligence.db'
        self.health_checks = {
            'database': self.check_database,
            'manifests': self.check_manifests,
            'hooks': self.check_hooks,
            'learning': self.check_learning
        }
        
    def run_health_checks(self) -> Dict[str, Dict]:
        """Run all health checks"""
        results = {}
        
        for component, check_func in self.health_checks.items():
            try:
                status, message, metrics = check_func()
                results[component] = {
                    'status': status,
                    'message': message,
                    'metrics': metrics
                }
                
                # Record in database
                self.record_health(component, status, message, metrics)
                
                # Alert if degraded or failed
                if status in ['degraded', 'failed']:
                    self.create_health_alert(component, status, message)
                    
            except Exception as e:
                results[component] = {
                    'status': 'failed',
                    'message': str(e),
                    'metrics': {}
                }
                self.create_health_alert(component, 'failed', str(e))
        
        return results
    
    def check_database(self) -> Tuple[str, str, Dict]:
        """Check database health"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                # Check size
                size_mb = self.db_path.stat().st_size / (1024 * 1024)
                
                # Check recent activity
                recent = conn.execute("""
                    SELECT COUNT(*) FROM context_usage
                    WHERE timestamp > datetime('now', '-1 hour')
                """).fetchone()[0]
                
                # Check failure rate
                failures = conn.execute("""
                    SELECT 
                        (SUM(CASE WHEN success = 0 THEN 1 ELSE 0 END) * 100.0 / COUNT(*)) as failure_rate
                    FROM context_usage
                    WHERE timestamp > datetime('now', '-1 hour')
                """).fetchone()[0] or 0
                
                status = 'healthy'
                if failures > 30:
                    status = 'degraded'
                elif failures > 50:
                    status = 'failed'
                
                return status, f"DB: {size_mb:.1f}MB, Recent: {recent}, Failures: {failures:.1f}%", {
                    'size_mb': size_mb,
                    'recent_activity': recent,
                    'failure_rate': failures
                }
                
        except Exception as e:
            return 'failed', str(e), {}
    
    def check_manifests(self) -> Tuple[str, str, Dict]:
        """Check manifest generation health"""
        manifest_dir = Path.home() / '.claude' / 'manifests'
        
        if not manifest_dir.exists():
            return 'failed', 'Manifest directory missing', {}
        
        manifests = list(manifest_dir.glob('*.json'))
        
        # Check freshness
        fresh_count = 0
        for manifest in manifests:
            age_hours = (time.time() - manifest.stat().st_mtime) / 3600
            if age_hours < 4:  # Manifests should refresh every 4 hours
                fresh_count += 1
        
        freshness = (fresh_count / len(manifests) * 100) if manifests else 0
        
        status = 'healthy' if freshness > 80 else 'degraded' if freshness > 50 else 'failed'
        
        return status, f"{len(manifests)} manifests, {freshness:.0f}% fresh", {
            'manifest_count': len(manifests),
            'freshness_percent': freshness
        }
    
    def check_hooks(self) -> Tuple[str, str, Dict]:
        """Check if hooks are properly registered"""
        settings_path = Path.home() / '.claude' / 'settings.json'
        
        if not settings_path.exists():
            return 'failed', 'Settings file missing', {}
        
        import json
        with open(settings_path) as f:
            settings = json.load(f)
        
        hooks = settings.get('hooks', {})
        required_hooks = ['pre-agent', 'post-edit']
        
        missing = []
        for hook in required_hooks:
            if hook not in hooks or not hooks[hook]:
                missing.append(hook)
        
        if not missing:
            status = 'healthy'
            message = 'All required hooks registered'
        else:
            status = 'degraded'
            message = f'Missing hooks: {", ".join(missing)}'
        
        return status, message, {'missing_hooks': missing}
    
    def check_learning(self) -> Tuple[str, str, Dict]:
        """Check if learning is happening"""
        with sqlite3.connect(self.db_path) as conn:
            # Check if patterns are being updated
            recent_patterns = conn.execute("""
                SELECT COUNT(*) FROM learning_patterns
                WHERE updated_at > datetime('now', '-24 hours')
            """).fetchone()[0]
            
            # Check if relevance scores are being recorded
            recent_scores = conn.execute("""
                SELECT COUNT(*) FROM relevance_scores
                WHERE timestamp > datetime('now', '-24 hours')
            """).fetchone()[0]
        
        if recent_patterns > 0 and recent_scores > 0:
            status = 'healthy'
            message = f'Learning active: {recent_patterns} patterns, {recent_scores} scores'
        elif recent_patterns > 0 or recent_scores > 0:
            status = 'degraded'
            message = 'Learning partially active'
        else:
            status = 'failed'
            message = 'No learning activity detected'
        
        return status, message, {
            'recent_patterns': recent_patterns,
            'recent_scores': recent_scores
        }
    
    def record_health(self, component: str, status: str, message: str, metrics: Dict):
        """Record health status to database"""
        with sqlite3.connect(self.db_path) as conn:
            conn.execute("""
                INSERT INTO system_health (component, status, message, metrics)
                VALUES (?, ?, ?, ?)
            """, (component, status, message, json.dumps(metrics)))
    
    def create_health_alert(self, component: str, status: str, message: str):
        """Create alert for health issues"""
        severity = 'critical' if status == 'failed' else 'warning'
        
        with sqlite3.connect(self.db_path) as conn:
            conn.execute("""
                INSERT INTO alerts (severity, component, message, details)
                VALUES (?, ?, ?, ?)
            """, (severity, f'health-{component}', message, json.dumps({'status': status})))
        
        # Audio notification for failures
        if status == 'failed':
            subprocess.run(['say', f"PRISM component {component} has failed"], capture_output=True)
```

---

## üîÑ Component 4: Cross-Repository Intelligence

### **4.1 Pattern Learner** (Learns across projects)

```python
# prism/src/cross_repo_intelligence.py

import sqlite3
from pathlib import Path
from typing import Dict, List
import subprocess
import json

class CrossRepositoryIntelligence:
    """Learns patterns across all repositories"""
    
    def __init__(self):
        self.db_path = Path.home() / '.claude' / 'prism' / 'intelligence.db'
        
    def scan_repository(self, repo_path: Path) -> Dict:
        """Scan a repository for patterns"""
        patterns = {
            'file_structure': self.analyze_structure(repo_path),
            'dependencies': self.analyze_dependencies(repo_path),
            'code_patterns': self.analyze_code_patterns(repo_path),
            'test_patterns': self.analyze_test_patterns(repo_path)
        }
        
        # Store patterns
        self.store_patterns(repo_path.name, patterns)
        
        return patterns
    
    def analyze_structure(self, repo_path: Path) -> Dict:
        """Analyze repository structure"""
        structure = {
            'directories': [],
            'file_types': {},
            'patterns': []
        }
        
        for path in repo_path.rglob('*'):
            if path.is_file() and not any(part.startswith('.') for part in path.parts):
                ext = path.suffix
                structure['file_types'][ext] = structure['file_types'].get(ext, 0) + 1
        
        # Detect patterns
        if (repo_path / 'src').exists():
            structure['patterns'].append('src-based')
        if (repo_path / 'lib').exists():
            structure['patterns'].append('lib-based')
        if (repo_path / 'tests').exists() or (repo_path / 'test').exists():
            structure['patterns'].append('has-tests')
        
        return structure
    
    def analyze_dependencies(self, repo_path: Path) -> Dict:
        """Analyze project dependencies"""
        deps = {
            'package_managers': [],
            'languages': [],
            'frameworks': []
        }
        
        # Check for package files
        if (repo_path / 'package.json').exists():
            deps['package_managers'].append('npm')
            deps['languages'].append('javascript')
            
            # Parse package.json for frameworks
            with open(repo_path / 'package.json') as f:
                pkg = json.load(f)
                dependencies = {**pkg.get('dependencies', {}), **pkg.get('devDependencies', {})}
                
                if 'react' in dependencies:
                    deps['frameworks'].append('react')
                if 'vue' in dependencies:
                    deps['frameworks'].append('vue')
                if 'next' in dependencies:
                    deps['frameworks'].append('nextjs')
        
        if (repo_path / 'requirements.txt').exists():
            deps['package_managers'].append('pip')
            deps['languages'].append('python')
        
        if (repo_path / 'Cargo.toml').exists():
            deps['package_managers'].append('cargo')
            deps['languages'].append('rust')
        
        return deps
    
    def store_patterns(self, repo_name: str, patterns: Dict):
        """Store patterns in database"""
        with sqlite3.connect(self.db_path) as conn:
            for pattern_type, pattern_data in patterns.items():
                if isinstance(pattern_data, dict):
                    for key, value in pattern_data.items():
                        conn.execute("""
                            INSERT INTO repository_patterns (repository, pattern_type, pattern_value, frequency)
                            VALUES (?, ?, ?, ?)
                            ON CONFLICT(repository, pattern_type, pattern_value) 
                            DO UPDATE SET frequency = frequency + 1, last_seen = CURRENT_TIMESTAMP
                        """, (repo_name, f"{pattern_type}.{key}", str(value), 1))
    
    def get_recommendations(self, current_repo: str) -> List[Dict]:
        """Get recommendations based on cross-repo patterns"""
        with sqlite3.connect(self.db_path) as conn:
            # Find similar repositories
            similar = conn.execute("""
                SELECT DISTINCT repository 
                FROM repository_patterns
                WHERE pattern_value IN (
                    SELECT pattern_value FROM repository_patterns
                    WHERE repository = ?
                )
                AND repository != ?
                LIMIT 5
            """, (current_repo, current_repo)).fetchall()
            
            recommendations = []
            
            # Get patterns from similar repos that current doesn't have
            for (similar_repo,) in similar:
                patterns = conn.execute("""
                    SELECT pattern_type, pattern_value, confidence
                    FROM repository_patterns
                    WHERE repository = ?
                    AND pattern_value NOT IN (
                        SELECT pattern_value FROM repository_patterns
                        WHERE repository = ?
                    )
                    ORDER BY confidence DESC
                    LIMIT 3
                """, (similar_repo, current_repo)).fetchall()
                
                for pattern_type, pattern_value, confidence in patterns:
                    recommendations.append({
                        'source': similar_repo,
                        'pattern': pattern_type,
                        'value': pattern_value,
                        'confidence': confidence,
                        'recommendation': f"Consider adopting {pattern_value} (used in {similar_repo})"
                    })
        
        return recommendations
```

---

## üö¶ Component 5: Activation Script

### **5.1 One-Command Activation**

```bash
#!/bin/bash
# prism/activate.sh

echo "üîÆ Activating PRISM Unified Intelligence System..."

# 1. Create database
echo "üìä Creating intelligence database..."
mkdir -p ~/.claude/prism
python3 << EOF
import sqlite3
from pathlib import Path

db_path = Path.home() / '.claude' / 'prism' / 'intelligence.db'
schema_path = Path(__file__).parent / 'database' / 'schema.sql'

with sqlite3.connect(db_path) as conn:
    with open(schema_path) as f:
        conn.executescript(f.read())
        
print("‚úÖ Database created")
EOF

# 2. Install dependencies
echo "üì¶ Installing dependencies..."
pip install rich watchdog -q

# 3. Register hooks
echo "üîó Registering hooks..."
python3 << EOF
import json
from pathlib import Path

settings_path = Path.home() / '.claude' / 'settings.json'
settings = {}

if settings_path.exists():
    with open(settings_path) as f:
        settings = json.load(f)

if 'hooks' not in settings:
    settings['hooks'] = {}

# Add PRISM hooks
prism_hooks = [
    "python3 ~/.claude/hooks/universal_interceptor.py",
    "python3 ~/.claude/hooks/context-dna-loader.py",
    "python3 ~/.claude/hooks/health_monitor.py"
]

if 'pre-agent' not in settings['hooks']:
    settings['hooks']['pre-agent'] = []

for hook in prism_hooks:
    if hook not in settings['hooks']['pre-agent']:
        settings['hooks']['pre-agent'].append(hook)

with open(settings_path, 'w') as f:
    json.dump(settings, f, indent=2)
    
print("‚úÖ Hooks registered")
EOF

# 4. Copy files to proper locations
echo "üìÅ Installing PRISM components..."
cp -r src/* ~/.claude/hooks/
cp -r commands/* ~/.claude/commands/

# 5. Run initial health check
echo "üè• Running health check..."
python3 ~/.claude/hooks/health_monitor.py

# 6. Start dashboard in background
echo "üìä Starting dashboard..."
nohup python3 ~/.claude/hooks/dashboard.py > /tmp/prism_dashboard.log 2>&1 &

echo "
‚ú® PRISM Unified Intelligence System Activated! ‚ú®

üìä Dashboard: Run '/prism status' to view metrics
üîç Health: Run '/prism health' for system check  
üìà Learning: Automatic - gets smarter with every use
üö® Alerts: Audio + terminal notifications enabled

No more silent failures. Everything is observable.
"
```

---

## üìà Success Metrics

### **Observable Results You'll See:**

1. **Real-time Dashboard** (`/prism status`)
   - Task success rates
   - Context optimization metrics
   - Failure alerts
   - Agent performance

2. **Automatic Alerts**
   - Audio notifications for failures
   - Terminal alerts for issues
   - Email/Slack integration ready

3. **Learning Visibility** (`/prism learn`)
   - Pattern recognition progress
   - Context effectiveness scores
   - Cross-repo insights

4. **Health Monitoring** (`/prism health`)
   - Component status (green/yellow/red)
   - Database growth tracking
   - Hook registration status
   - Manifest freshness

---

## üéØ The Complete Solution

This unified system:

1. **Collects automatically** - Every agent execution tracked
2. **Learns continuously** - Patterns improve with use
3. **Alerts immediately** - No silent failures
4. **Shows everything** - Real-time observable dashboard
5. **Works across repos** - Learns from all projects
6. **Self-monitors** - Health checks prevent degradation

**Result**: A truly intelligent system that gets smarter every day while providing complete visibility into its operation.

**No more blind spots. No more silent failures. Just intelligent, observable automation.**